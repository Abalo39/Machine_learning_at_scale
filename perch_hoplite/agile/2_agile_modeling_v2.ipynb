{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXQAcreKedWU"
      },
      "outputs": [],
      "source": [
        "# Install hoplite and TF 2.20\n",
        "!pip install --upgrade pip\n",
        "!pip install git+https://github.com/google-research/perch-hoplite.git\n",
        "!pip install tensorflow~=2.20.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujDH4aTw3shB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from etils import epath\n",
        "\n",
        "# Hoplite imports\n",
        "from perch_hoplite.agile import audio_loader\n",
        "from perch_hoplite.agile import classifier\n",
        "from perch_hoplite.agile import classifier_data\n",
        "from perch_hoplite.agile import embedding_display\n",
        "from perch_hoplite.agile import source_info\n",
        "from perch_hoplite.db  import brutalism\n",
        "from perch_hoplite.db import score_functions\n",
        "from perch_hoplite.db  import search_results\n",
        "from perch_hoplite.db import sqlite_usearch_impl\n",
        "from perch_hoplite.zoo import model_configs"
      ],
      "metadata": {
        "id": "xIcs_krw3skD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ueTcznPlWjA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy hoplite database locally.\n",
        "intaka_path = epath.Path('gs://chirp-public-bucket/soundscapes/intaka')\n",
        "\n",
        "# Copy the hoplite database to the Colab local storage.\n",
        "# The usearch.index file is large, so this may take a minute.\n",
        "print(\"Copying database files...\")\n",
        "for fp in intaka_path.glob('hoplite*'):\n",
        "  print(f\"Copying {fp}...\")\n",
        "  with fp.open('rb') as f:\n",
        "    with open(fp.name, 'wb') as g:\n",
        "      g.write(f.read())\n",
        "\n",
        "print(\"Copying search index (this may take a moment)...\")\n",
        "with (intaka_path / 'usearch.index').open('rb') as f:\n",
        "  with open('usearch.index', 'wb') as g:\n",
        "    g.write(f.read())\n",
        "\n",
        "# Update the DB with override values.\n",
        "# We point the db to the google cloud bucket containing the audio files.\n",
        "db_path = '/content'\n",
        "db = sqlite_usearch_impl.SQLiteUsearchDB.create(db_path)\n",
        "\n",
        "# Update Model Config\n",
        "model_cfg = db.get_metadata('model_config')\n",
        "model_cfg.model_config.tfhub_path = 'google/bird-vocalization-classifier/tensorFlow2/perch_v2_cpu'\n",
        "model_cfg.model_config.tfhub_version = 1\n",
        "db.insert_metadata('model_config', model_cfg)\n",
        "\n",
        "# Update Audio Sources Config\n",
        "sources_cfg = db.get_metadata('audio_sources')\n",
        "sources_cfg.audio_globs[0]['base_path'] = 'gs://chirp-public-bucket/soundscapes/intaka'\n",
        "db.insert_metadata('audio_sources', sources_cfg)\n",
        "\n",
        "db.commit()\n",
        "print(\"SUCCESS: Database setup complete.\")"
      ],
      "metadata": {
        "id": "qpcj3nYCDwV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotator_id = 'linnaeus'\n",
        "\n",
        "# 1. Get configuration from the Intaka DB\n",
        "db_model_config = db.get_metadata('model_config')\n",
        "embed_config = db.get_metadata('audio_sources')\n",
        "\n",
        "# 2. Initialize the model\n",
        "print(\"Initializing model...\")\n",
        "model_class = model_configs.get_model_class(db_model_config.model_key)\n",
        "embedding_model = model_class.from_config(db_model_config.model_config)\n",
        "\n",
        "# 3. Initialize the audio loader\n",
        "audio_sources = source_info.AudioSources.from_config_dict(embed_config)\n",
        "if hasattr(embedding_model, 'window_size_s'):\n",
        "  window_size_s = embedding_model.window_size_s\n",
        "else:\n",
        "  window_size_s = 5.0\n",
        "\n",
        "audio_filepath_loader = audio_loader.make_filepath_loader(\n",
        "    audio_sources=audio_sources,\n",
        "    window_size_s=window_size_s,\n",
        "    sample_rate_hz=embedding_model.sample_rate,\n",
        ")\n",
        "print(\"SUCCESS: Model and Loader initialized.\")"
      ],
      "metadata": {
        "id": "fq-uI9IUDwZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_a6XnRJs3snS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load query audio.\n",
        "# using Red-eyed Dove (xc746686) as requested for the Intaka session\n",
        "query_uri = 'xc746686'\n",
        "query_label = 'redeye'\n",
        "\n",
        "print(f\"Loading query: {query_uri} ({query_label})\")\n",
        "query = embedding_display.QueryDisplay(\n",
        "    uri=query_uri, offset_s=0.0, window_size_s=5.0, sample_rate_hz=32000)\n",
        "_ = query.display_interactive()"
      ],
      "metadata": {
        "id": "7n6HE6We3sqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJd6-Zay3sw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mT6kYEBbbhpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display 50 Audio Results (Fixed)\n",
        "from perch_hoplite.agile import embedding_display\n",
        "from perch_hoplite.db import search_results\n",
        "\n",
        "query_label = 'redeye'\n",
        "num_results = 50\n",
        "\n",
        "print(f\"Searching for {num_results} similar audio clips\")\n",
        "\n",
        "# 1 Ensure we have the search results\n",
        "query_embedding = embedding_model.embed(query.get_audio_window()).embeddings[0, 0]\n",
        "ann_matches = db.ui.search(query_embedding, count=num_results)\n",
        "\n",
        "results = search_results.TopKSearchResults(top_k=num_results)\n",
        "for k, d in zip(ann_matches.keys, ann_matches.distances):\n",
        "  results.update(search_results.SearchResult(k, d))\n",
        "\n",
        "# 2. Create and Display the Audio Players\n",
        "print(\"Generating audio players... (This might take a few seconds)\")\n",
        "display_results = embedding_display.EmbeddingDisplayGroup.from_search_results(\n",
        "    results, db, sample_rate_hz=32000, frame_rate=100,\n",
        "    audio_loader=audio_filepath_loader)\n",
        "\n",
        "# 3. Show the widgets\n",
        "print(\"READY: Please listen and click 'redeye' on the matching birds below.\")\n",
        "display_results.display(positive_labels=[query_label])\n",
        "# ************************************************\n",
        "# MANUAL STEP: LISTEN AND CLICK 'redeye' LABELS HERE\n",
        "# ************************************************"
      ],
      "metadata": {
        "id": "J5AjurtZbhrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JRK88LljZsFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Save Data Labels\n",
        "# Define your name/ID\n",
        "annotator_id = 'linnaeus'\n",
        "\n",
        "prev_lbls, new_lbls = 0, 0\n",
        "print(\"Harvesting your labels...\")\n",
        "\n",
        "# This grabs the 'green' clicks from the display you just used\n",
        "try:\n",
        "    for lbl in display_results.harvest_labels(annotator_id):\n",
        "        check = db.insert_label(lbl, skip_duplicates=True)\n",
        "        new_lbls += check\n",
        "        prev_lbls += (1 - check)\n",
        "\n",
        "    print(f'\\nSUCCESS: New labels saved: {new_lbls}')\n",
        "    print(f'Previous labels (duplicates skipped): {prev_lbls}')\n",
        "\n",
        "    if new_lbls == 0 and prev_lbls == 0:\n",
        "        print(\"WARNING: No labels were saved. Did you click the 'redeye' buttons?\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"ERROR: Please run the 'Display Results' cell first.\")"
      ],
      "metadata": {
        "id": "-XzEqoQjZsIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dOG5Uh0mcf7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eDWW5XkIcf-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DG6P7slVcgBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "blgqyVNOcaQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcYGx6qPcaby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Search for Bird #2: Laughing Dove\n",
        "from perch_hoplite.agile import embedding_display\n",
        "from perch_hoplite.db import search_results\n",
        "\n",
        "# 1. Setup for bird 2 (Laughing Dove)\n",
        "query_uri = 'xc666993'   # Id for Laughing Dove\n",
        "query_label = 'laudov'   # Label for Laughing Dove\n",
        "\n",
        "print(f\"Loading query: {query_uri} ({query_label})\")\n",
        "query = embedding_display.QueryDisplay(\n",
        "    uri=query_uri, offset_s=0.0, window_size_s=5.0, sample_rate_hz=32000)\n",
        "_ = query.display_interactive()\n",
        "\n",
        "# 2. SEARCH\n",
        "print(f\"Searching for 50 matches for {query_label}...\")\n",
        "query_embedding = embedding_model.embed(query.get_audio_window()).embeddings[0, 0]\n",
        "ann_matches = db.ui.search(query_embedding, count=50)\n",
        "\n",
        "results = search_results.TopKSearchResults(top_k=50)\n",
        "for k, d in zip(ann_matches.keys, ann_matches.distances):\n",
        "  results.update(search_results.SearchResult(k, d))\n",
        "\n",
        "# 3. DISPLAY PLAYERS\n",
        "print(\"READY: Listen and click 'laudov' for the correct matches below.\")\n",
        "display_results = embedding_display.EmbeddingDisplayGroup.from_search_results(\n",
        "    results, db, sample_rate_hz=32000, frame_rate=100,\n",
        "    audio_loader=audio_filepath_loader)\n",
        "display_results.display(positive_labels=[query_label])\n",
        "# ************************************************\n",
        "# MANUAL STEP: LISTEN AND CLICK 'laudov' LABELS HERE\n",
        "# ************************************************"
      ],
      "metadata": {
        "id": "V27Uz93IZsKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save Labels for Bird 2\n",
        "annotator_id = 'linnaeus'\n",
        "\n",
        "prev_lbls, new_lbls = 0, 0\n",
        "print(f\"Harvesting labels for {query_label}...\")\n",
        "\n",
        "try:\n",
        "    for lbl in display_results.harvest_labels(annotator_id):\n",
        "        check = db.insert_label(lbl, skip_duplicates=True)\n",
        "        new_lbls += check\n",
        "        prev_lbls += (1 - check)\n",
        "\n",
        "    print(f'\\nSUCCESS: Added {new_lbls} new labels.')\n",
        "\n",
        "    # Recalculate total labels by iterating through the db's public methods\n",
        "    all_current_labels = []\n",
        "    for cls_name in db.get_classes():\n",
        "        idxes_for_class = db.get_embeddings_by_label(cls_name)\n",
        "        for idx in idxes_for_class:\n",
        "            labels_for_embedding = db.get_labels(idx)\n",
        "            all_current_labels.extend(labels_for_embedding)\n",
        "\n",
        "    total_labels_count = len(all_current_labels)\n",
        "    print(f'Total labels in database (Birds 1 & 2): {total_labels_count}')\n",
        "\n",
        "except NameError:\n",
        "    print(\"ERROR: Please run the 'Search for Bird #2' cell first.\")"
      ],
      "metadata": {
        "id": "LOuDvAqoZsOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GPSp5RhiZykA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Final Train & Export CSV\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from perch_hoplite.agile import classifier_data, classifier\n",
        "\n",
        "# 1. TRAIN (Detects all labeled birds)\n",
        "print(\"Training classifier on ALL birds...\")\n",
        "data_manager = classifier_data.AgileDataManager(\n",
        "    target_labels=None, # Automatically finds all labels saved to the DB\n",
        "    db=db,\n",
        "    train_ratio=0.9,\n",
        "    min_eval_examples=1,\n",
        "    batch_size=128,\n",
        "    weak_negatives_batch_size=128,\n",
        "    rng=np.random.default_rng(seed=5))\n",
        "\n",
        "print(f\"Found targets: {data_manager.get_target_labels()}\")\n",
        "\n",
        "linear_classifier, eval_scores = classifier.train_linear_classifier(\n",
        "    data_manager=data_manager,\n",
        "    learning_rate=1e-3,\n",
        "    weak_neg_weight=0.05,\n",
        "    num_train_steps=128,\n",
        ")\n",
        "print(f\"Final Top-1 Accuracy: {eval_scores['top1_acc']:.3f}\\n\")\n",
        "\n",
        "\n",
        "# 2. EXPORT CSV\n",
        "print(\"Creating Final CSV...\")\n",
        "data_records = []\n",
        "annotator_id = 'linnaeus' # Ensure this matches your ID\n",
        "\n",
        "for cls in db.get_classes():\n",
        "  idxes = db.get_embeddings_by_label(cls)\n",
        "  for idx in idxes:\n",
        "    s = db.get_embedding_source(idx)\n",
        "    for lbl in db.get_labels(idx):\n",
        "      data_records.append({\n",
        "          'source_id': s.source_id,\n",
        "          'offset_s': s.offsets[0],\n",
        "          'label': lbl.label,\n",
        "          'type': lbl.type,\n",
        "          'annotator': annotator_id\n",
        "      })\n",
        "\n",
        "if data_records:\n",
        "    df = pd.DataFrame(data_records)\n",
        "    csv_filename = 'intaka_labeled_segments_final.csv'\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "    print(f\"SUCCESS: Saved {len(df)} labels to {csv_filename}\")\n",
        "    # This command will automatically prompt you to download the CSV in Colab\n",
        "    files.download(csv_filename)\n",
        "else:\n",
        "    print(\"No labels found. Did you run all the 'Save Labels' steps?\")"
      ],
      "metadata": {
        "id": "gY3DnOtqZyud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SU1503dHZ2wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Final Train & Export CSV\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from perch_hoplite.agile import classifier_data, classifier\n",
        "\n",
        "# 1. TRAIN (Detects all labeled birds)\n",
        "print(\"Training classifier on ALL birds...\")\n",
        "data_manager = classifier_data.AgileDataManager(\n",
        "    target_labels=None, # Automatically finds all labels saved to the DB\n",
        "    db=db,\n",
        "    train_ratio=0.9,\n",
        "    min_eval_examples=1,\n",
        "    batch_size=128,\n",
        "    weak_negatives_batch_size=128,\n",
        "    rng=np.random.default_rng(seed=5))\n",
        "\n",
        "print(f\"Found targets: {data_manager.get_target_labels()}\")\n",
        "\n",
        "linear_classifier, eval_scores = classifier.train_linear_classifier(\n",
        "    data_manager=data_manager,\n",
        "    learning_rate=1e-3,\n",
        "    weak_neg_weight=0.05,\n",
        "    num_train_steps=128,\n",
        ")\n",
        "print(f\"Final Top-1 Accuracy: {eval_scores['top1_acc']:.3f}\\n\")\n",
        "\n",
        "\n",
        "# 2. EXPORT CSV\n",
        "print(\"Creating Final CSV...\")\n",
        "data_records = []\n",
        "annotator_id = 'linnaeus' # Ensure this matches your ID\n",
        "\n",
        "for cls in db.get_classes():\n",
        "  idxes = db.get_embeddings_by_label(cls)\n",
        "  for idx in idxes:\n",
        "    s = db.get_embedding_source(idx)\n",
        "    for lbl in db.get_labels(idx):\n",
        "      data_records.append({\n",
        "          'source_id': s.source_id,\n",
        "          'offset_s': s.offsets[0],\n",
        "          'label': lbl.label,\n",
        "          'type': lbl.type,\n",
        "          'annotator': annotator_id\n",
        "      })\n",
        "\n",
        "if data_records:\n",
        "    df = pd.DataFrame(data_records)\n",
        "    csv_filename = 'intaka_labeled_segments_final.csv'\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "    print(f\"SUCCESS: Saved {len(df)} labels to {csv_filename}\")\n",
        "    # This command will automatically prompt you to download the CSV in Colab\n",
        "    files.download(csv_filename)\n",
        "else:\n",
        "    print(\"No labels found. Did you run all the 'Save Labels' steps?\")"
      ],
      "metadata": {
        "id": "_Xpz61TbZ2z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qwq7AJ19Z5pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yntknEWZ5rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7icHRXtoZ5tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nKulpI83Z5wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X8zVo45-Z5zB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}