{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abalo39/Machine_learning_at_scale/blob/main/perch_hoplite/agile/2_agile_modeling_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXQAcreKedWU"
      },
      "outputs": [],
      "source": [
        "#@title Imports. { vertical-output: true }\n",
        "\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from etils import epath\n",
        "\n",
        "# Hoplite imports\n",
        "from perch_hoplite.agile import audio_loader\n",
        "from perch_hoplite.agile import classifier\n",
        "from perch_hoplite.agile import classifier_data\n",
        "from perch_hoplite.agile import embedding_display\n",
        "from perch_hoplite.agile import source_info\n",
        "from perch_hoplite.db  import brutalism\n",
        "from perch_hoplite.db import score_functions\n",
        "from perch_hoplite.db  import search_results\n",
        "from perch_hoplite.db import sqlite_usearch_impl\n",
        "from perch_hoplite.zoo import model_configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a1d7741"
      },
      "source": [
        "#@title Load query audio. { vertical-output: true }\n",
        "\n",
        "#@markdown The `query_uri` can be a URL, filepath, or Xeno-Canto ID\n",
        "#@markdown (like `xc777802`, containing an Eastern Whipbird (`easwhi1`)).\n",
        "query_uri = 'xc777802'  #@param {type:'string'}\n",
        "query_label = 'easwhi1'  #@param {type:'string'}\n",
        "\n",
        "query = embedding_display.QueryDisplay(\n",
        "    uri=query_uri, offset_s=0.0, window_size_s=5.0, sample_rate_hz=32000)\n",
        "_ = query.display_interactive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install hoplite and TF 2.20\n",
        "!pip install --upgrade pip\n",
        "!pip install git+https://github.com/google-research/perch-hoplite.git\n",
        "!pip install tensorflow~=2.20.0"
      ],
      "metadata": {
        "id": "qB8fvgk6SSjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujDH4aTw3shB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy hoplite database locally.\n",
        "from etils import epath\n",
        "import os\n",
        "from perch_hoplite.db import sqlite_usearch_impl\n",
        "intaka_path = epath.Path('gs://chirp-public-bucket/soundscapes/intaka')\n",
        "\n",
        "# Copy the hoplite database to the Colab local storage.\n",
        "# The usearch.index file is 3.6Gb, so takes a couple minutes to download.\n",
        "# Files are placed in `/content` directory.\n",
        "for fp in intaka_path.glob('hoplite*'):\n",
        "  print(fp)\n",
        "  with fp.open('rb') as f:\n",
        "    with open(fp.name, 'wb') as g:\n",
        "      g.write(f.read())\n",
        "with (intaka_path / 'usearch.index').open('rb') as f:\n",
        "  print(intaka_path / 'usearch.index')\n",
        "  with open('usearch.index', 'wb') as g:\n",
        "    %time g.write(f.read())\n",
        "\n",
        "# Update the DB with some override values...\n",
        "# Need to use the perch_v2_cpu model, and point the db to the google cloud\n",
        "# bucket containing the data.\n",
        "db_path = '/content'\n",
        "db = sqlite_usearch_impl.SQLiteUsearchDB.create(db_path)\n",
        "\n",
        "model_cfg = db.get_metadata('model_config')\n",
        "model_cfg.model_config.tfhub_path = 'google/bird-vocalization-classifier/tensorFlow2/perch_v2_cpu'\n",
        "model_cfg.model_config.tfhub_version = 1\n",
        "db.insert_metadata('model_config', model_cfg)\n",
        "\n",
        "sources_cfg = db.get_metadata('audio_sources')\n",
        "sources_cfg.audio_globs[0]['base_path'] = 'gs://chirp-public-bucket/soundscapes/intaka'\n",
        "db.insert_metadata('audio_sources', sources_cfg)\n",
        "\n",
        "db.commit()"
      ],
      "metadata": {
        "id": "xIcs_krw3skD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_a6XnRJs3snS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Model and Audio Loader { vertical-output: true }\n",
        "from perch_hoplite.agile import source_info\n",
        "from perch_hoplite.agile import audio_loader\n",
        "from perch_hoplite.zoo import model_configs\n",
        "\n",
        "#@markdown Identifier (eg, name) to attach to labels produced during validation.\n",
        "annotator_id = 'linnaeus'  #@param {type:'string'}\n",
        "\n",
        "# 1. Get configuration from the Intaka DB\n",
        "# This reads the settings saved in the database you just downloaded.\n",
        "db_model_config = db.get_metadata('model_config')\n",
        "embed_config = db.get_metadata('audio_sources')\n",
        "\n",
        "# 2. Initialize the model\n",
        "# This loads the \"Perch\" bird classifier model.\n",
        "print(\"Initializing model...\")\n",
        "model_class = model_configs.get_model_class(db_model_config.model_key)\n",
        "embedding_model = model_class.from_config(db_model_config.model_config)\n",
        "\n",
        "# 3. Initialize the audio loader\n",
        "# This sets up the tool that fetches the actual audio files from Google Cloud so you can listen to them.\n",
        "audio_sources = source_info.AudioSources.from_config_dict(embed_config)\n",
        "if hasattr(embedding_model, 'window_size_s'):\n",
        "  window_size_s = embedding_model.window_size_s\n",
        "else:\n",
        "  window_size_s = 5.0\n",
        "\n",
        "audio_filepath_loader = audio_loader.make_filepath_loader(\n",
        "    audio_sources=audio_sources,\n",
        "    window_size_s=window_size_s,\n",
        "    sample_rate_hz=embedding_model.sample_rate,\n",
        ")\n",
        "print(\"SUCCESS: Model and Loader initialized.\")"
      ],
      "metadata": {
        "id": "7n6HE6We3sqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Model and Audio Loader { vertical-output: true }\n",
        "# This cell prepares the tools needed for search and visualization using the DB created above.\n",
        "\n",
        "annotator_id = 'linnaeus'  #@param {type:'string'}\n",
        "\n",
        "# Get configuration from the Intaka DB\n",
        "db_model_config = db.get_metadata('model_config')\n",
        "embed_config = db.get_metadata('audio_sources')\n",
        "\n",
        "# Initialize the model\n",
        "model_class = model_configs.get_model_class(db_model_config.model_key)\n",
        "embedding_model = model_class.from_config(db_model_config.model_config)\n",
        "\n",
        "# Initialize the audio loader (fetches audio from Google Cloud)\n",
        "audio_sources = source_info.AudioSources.from_config_dict(embed_config)\n",
        "if hasattr(embedding_model, 'window_size_s'):\n",
        "  window_size_s = embedding_model.window_size_s\n",
        "else:\n",
        "  window_size_s = 5.0\n",
        "\n",
        "audio_filepath_loader = audio_loader.make_filepath_loader(\n",
        "    audio_sources=audio_sources,\n",
        "    window_size_s=window_size_s,\n",
        "    sample_rate_hz=embedding_model.sample_rate,\n",
        ")\n",
        "print(\"Model and Loader initialized.\")"
      ],
      "metadata": {
        "id": "ijcCAlMc3stX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJd6-Zay3sw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p8m8V4yc3s1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mbW6J9nE3t9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m_WEsBA03uAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oDhNqLWf3uDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hlmVduEj3s40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O_qdWXvy3s8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uF9Vkra13s_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ww3Hm8PH6YGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pcImpj3o6YJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C7uSyZ4Y6YNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOfIm9tD6YQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftm-42wu6YTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lEnjKkfG6YWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwMPCoA-6YY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MelbazUk6Yc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CAgX5Ur_6Ygm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "grDg5JXg6YkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f29ef1c"
      },
      "source": [
        "#@title Load model and connect to database. { vertical-output: true }\n",
        "\n",
        "#@markdown Location of database containing audio embeddings.\n",
        "db_path = '/content'  #@param {type:'string'}\n",
        "#@markdown Identifier (eg, name) to attach to labels produced during validation.\n",
        "annotator_id = 'linnaeus'  #@param {type:'string'}\n",
        "\n",
        "db = sqlite_usearch_impl.SQLiteUsearchDB.create(db_path)\n",
        "db_model_config = db.get_metadata('model_config')\n",
        "embed_config = db.get_metadata('audio_sources')\n",
        "model_class = model_configs.get_model_class(db_model_config.model_key)\n",
        "embedding_model = model_class.from_config(db_model_config.model_config)\n",
        "audio_sources = source_info.AudioSources.from_config_dict(embed_config)\n",
        "if hasattr(embedding_model, 'window_size_s'):\n",
        "  window_size_s = embedding_model.window_size_s\n",
        "else:\n",
        "  window_size_s = 5.0\n",
        "audio_filepath_loader = audio_loader.make_filepath_loader(\n",
        "    audio_sources=audio_sources,\n",
        "    window_size_s=window_size_s,\n",
        "    sample_rate_hz=embedding_model.sample_rate,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz63sWKEedWU"
      },
      "outputs": [],
      "source": [
        "#@title Load model and connect to database. { vertical-output: true }\n",
        "\n",
        "#@markdown Location of database containing audio embeddings.\n",
        "db_path = '/content'  #@param {type:'string'}\n",
        "#@markdown Identifier (eg, name) to attach to labels produced during validation.\n",
        "annotator_id = 'linnaeus'  #@param {type:'string'}\n",
        "\n",
        "db = sqlite_usearch_impl.SQLiteUsearchDB.create(db_path)\n",
        "db_model_config = db.get_metadata('model_config')\n",
        "embed_config = db.get_metadata('audio_sources')\n",
        "model_class = model_configs.get_model_class(db_model_config.model_key)\n",
        "embedding_model = model_class.from_config(db_model_config.model_config)\n",
        "audio_sources = source_info.AudioSources.from_config_dict(embed_config)\n",
        "if hasattr(embedding_model, 'window_size_s'):\n",
        "  window_size_s = embedding_model.window_size_s\n",
        "else:\n",
        "  window_size_s = 5.0\n",
        "audio_filepath_loader = audio_loader.make_filepath_loader(\n",
        "    audio_sources=audio_sources,\n",
        "    window_size_s=window_size_s,\n",
        "    sample_rate_hz=embedding_model.sample_rate,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVdLJJd9gnjo"
      },
      "source": [
        "# Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ig3L5dsy3mr"
      },
      "outputs": [],
      "source": [
        "#@title Load query audio. { vertical-output: true }\n",
        "\n",
        "#@markdown The `query_uri` can be a URL, filepath, or Xeno-Canto ID\n",
        "#@markdown (like `xc777802`, containing an Eastern Whipbird (`easwhi1`)).\n",
        "query_uri = 'xc777802'  #@param {type:'string'}\n",
        "query_label = 'easwhi1'  #@param {type:'string'}\n",
        "\n",
        "query = embedding_display.QueryDisplay(\n",
        "    uri=query_uri, offset_s=0.0, window_size_s=5.0, sample_rate_hz=32000)\n",
        "_ = query.display_interactive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy hoplite database locally.\n",
        "from etils import epath\n",
        "import os\n",
        "from perch_hoplite.db import sqlite_usearch_impl\n",
        "intaka_path = epath.Path('gs://chirp-public-bucket/soundscapes/intaka')\n",
        "\n",
        "# Copy the hoplite database to the Colab local storage.\n",
        "# The usearch.index file is 3.6Gb, so takes a couple minutes to download.\n",
        "# Files are placed in `/content` directory.\n",
        "for fp in intaka_path.glob('hoplite*'):\n",
        "  print(fp)\n",
        "  with fp.open('rb') as f:\n",
        "    with open(fp.name, 'wb') as g:\n",
        "      g.write(f.read())\n",
        "with (intaka_path / 'usearch.index').open('rb') as f:\n",
        "  print(intaka_path / 'usearch.index')\n",
        "  with open('usearch.index', 'wb') as g:\n",
        "    %time g.write(f.read())\n",
        "\n",
        "# Update the DB with some override values...\n",
        "# Need to use the perch_v2_cpu model, and point the db to the google cloud\n",
        "# bucket containing the data.\n",
        "db_path = '/content'\n",
        "db = sqlite_usearch_impl.SQLiteUsearchDB.create(db_path)\n",
        "\n",
        "model_cfg = db.get_metadata('model_config')\n",
        "model_cfg.model_config.tfhub_path = 'google/bird-vocalization-classifier/tensorFlow2/perch_v2_cpu'\n",
        "model_cfg.model_config.tfhub_version = 1\n",
        "db.insert_metadata('model_config', model_cfg)\n",
        "\n",
        "sources_cfg = db.get_metadata('audio_sources')\n",
        "sources_cfg.audio_globs[0]['base_path'] = 'gs://chirp-public-bucket/soundscapes/intaka'\n",
        "db.insert_metadata('audio_sources', sources_cfg)\n",
        "\n",
        "db.commit()"
      ],
      "metadata": {
        "id": "yuMSQFF-UP3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lBqrxoZ_UQCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHUJ_NwQWZNB"
      },
      "outputs": [],
      "source": [
        "#@title Embed the Query and Search. { vertical-output: true }\n",
        "\n",
        "#@markdown Number of results to find and display.\n",
        "num_results = 50  #@param\n",
        "query_embedding = embedding_model.embed(\n",
        "    query.get_audio_window()).embeddings[0, 0]\n",
        "\n",
        "#@markdown If checked, search for examples\n",
        "#@markdown near a particular target score.\n",
        "target_sampling = False  #@param {type: 'boolean'}\n",
        "\n",
        "#@markdown When target sampling, target this score.\n",
        "target_score = -1.0  #@param\n",
        "if not target_sampling:\n",
        "  target_score = None\n",
        "\n",
        "#@markdown If True, search the full DB. Otherwise, use approximate\n",
        "#@markdown nearest-neighbor search.\n",
        "exact_search = False  #@param {type: 'boolean'}\n",
        "\n",
        "if exact_search:\n",
        "  score_fn = score_functions.get_score_fn('dot', target_score=target_score)\n",
        "  results, all_scores = brutalism.threaded_brute_search(\n",
        "      db, query_embedding, num_results, score_fn=score_fn)\n",
        "  # TODO(tomdenton): Better histogram when target sampling.\n",
        "  _ = plt.hist(all_scores, bins=100)\n",
        "  hit_scores = [r.sort_score for r in results.search_results]\n",
        "  plt.scatter(hit_scores, np.zeros_like(hit_scores), marker='|',\n",
        "              color='r', alpha=0.5)\n",
        "else:\n",
        "  ann_matches = db.ui.search(query_embedding, count=num_results)\n",
        "  results = search_results.TopKSearchResults(top_k=num_results)\n",
        "  for k, d in zip(ann_matches.keys, ann_matches.distances):\n",
        "    results.update(search_results.SearchResult(k, d))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y21fWjEwXj68"
      },
      "outputs": [],
      "source": [
        "#@title Display Results. { vertical-output: true }\n",
        "\n",
        "display_results = embedding_display.EmbeddingDisplayGroup.from_search_results(\n",
        "    results, db, sample_rate_hz=32000, frame_rate=100,\n",
        "    audio_loader=audio_filepath_loader)\n",
        "display_results.display(positive_labels=[query_label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3sIkOqlXzKB"
      },
      "outputs": [],
      "source": [
        "#@title Save data labels. { vertical-output: true }\n",
        "\n",
        "prev_lbls, new_lbls = 0, 0\n",
        "for lbl in display_results.harvest_labels(annotator_id):\n",
        "  check = db.insert_label(lbl, skip_duplicates=True)\n",
        "  new_lbls += check\n",
        "  prev_lbls += (1 - check)\n",
        "print('\\nnew_lbls: ', new_lbls)\n",
        "print('\\nprev_lbls: ', prev_lbls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o65wpjvyYft-"
      },
      "source": [
        "# Classify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtsJkgcPYg6z"
      },
      "outputs": [],
      "source": [
        "#@title Classifier training. { vertical-output: true }\n",
        "\n",
        "#@markdown Set of labels to classify. If None, auto-populated from the DB.\n",
        "target_labels = None  #@param\n",
        "\n",
        "#@markdown Classifier traning hyperparams. These should not require tuning.\n",
        "learning_rate = 1e-3  #@param\n",
        "weak_neg_weight = 0.05  #@param\n",
        "l2_mu = 0.000  #@param\n",
        "num_steps = 128  #@param\n",
        "\n",
        "train_ratio = 0.9  #@param\n",
        "batch_size = 128  #@param\n",
        "weak_negatives_batch_size = 128  #@param\n",
        "loss_fn_name = 'bce'  #@param ['hinge', 'bce']\n",
        "\n",
        "data_manager = classifier_data.AgileDataManager(\n",
        "    target_labels=target_labels,\n",
        "    db=db,\n",
        "    train_ratio=train_ratio,\n",
        "    min_eval_examples=1,\n",
        "    batch_size=batch_size,\n",
        "    weak_negatives_batch_size=weak_negatives_batch_size,\n",
        "    rng=np.random.default_rng(seed=5))\n",
        "print('Training for target labels : ')\n",
        "print(data_manager.get_target_labels())\n",
        "linear_classifier, eval_scores = classifier.train_linear_classifier(\n",
        "    data_manager=data_manager,\n",
        "    learning_rate=learning_rate,\n",
        "    weak_neg_weight=weak_neg_weight,\n",
        "    num_train_steps=num_steps,\n",
        ")\n",
        "print('\\n' + '-' * 80)\n",
        "top1 = eval_scores['top1_acc']\n",
        "print(f'top-1      {top1:.3f}')\n",
        "rocauc = eval_scores['roc_auc']\n",
        "print(f'roc_auc    {rocauc:.3f}')\n",
        "cmap = eval_scores['cmap']\n",
        "print(f'cmap       {cmap:.3f}')\n",
        "\n",
        "# Save linear classifier.\n",
        "linear_classifier.save(os.path.join(db_path, 'agile_classifier_v2.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3N6dzhetkG1"
      },
      "outputs": [],
      "source": [
        "#@title Review Classifier Results. { vertical-output: true }\n",
        "\n",
        "#@markdown Number of results to find and display.\n",
        "target_label = 'easwhi1'  #@param {type:'string'}\n",
        "num_results = 50  #@param\n",
        "\n",
        "target_label_idx = data_manager.get_target_labels().index(target_label)\n",
        "class_query = linear_classifier.beta[:, target_label_idx]\n",
        "bias = linear_classifier.beta_bias[target_label_idx]\n",
        "\n",
        "#@markdown Number of (randomly selected) database entries to search over.\n",
        "sample_size = 1_000_000  #@param\n",
        "\n",
        "#@markdown Whether to use margin-sampling. If checked, search for examples\n",
        "#@markdown with logits near a particular target score (usually 0).\n",
        "margin_sampling = False  #@param {type: 'boolean'}\n",
        "\n",
        "#@markdown When margin sampling, target this logit.\n",
        "margin_target_score = -0.0  #@param\n",
        "if not margin_sampling:\n",
        "  margin_target_score = None\n",
        "score_fn = score_functions.get_score_fn(\n",
        "    'dot', bias=bias, target_score=margin_target_score)\n",
        "results, all_scores = brutalism.threaded_brute_search(\n",
        "    db, class_query, num_results, score_fn=score_fn,\n",
        "    sample_size=sample_size)\n",
        "\n",
        "# TODO(tomdenton): Better histogram when margin sampling.\n",
        "_ = plt.hist(all_scores, bins=100)\n",
        "hit_scores = [r.sort_score for r in results.search_results]\n",
        "plt.scatter(hit_scores, np.zeros_like(hit_scores), marker='|',\n",
        "            color='r', alpha=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiNoGhyoDF2v"
      },
      "outputs": [],
      "source": [
        "#@title Display Results. { vertical-output: true }\n",
        "\n",
        "display_results = embedding_display.EmbeddingDisplayGroup.from_search_results(\n",
        "    results, db, sample_rate_hz=32000, frame_rate=100,\n",
        "    audio_loader=audio_filepath_loader)\n",
        "display_results.display(positive_labels=[target_label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEk15jw_B8xL"
      },
      "outputs": [],
      "source": [
        "#@title Save data labels. { vertical-output: true }\n",
        "\n",
        "prev_lbls, new_lbls = 0, 0\n",
        "for lbl in display_results.harvest_labels(annotator_id):\n",
        "  check = db.insert_label(lbl, skip_duplicates=True)\n",
        "  new_lbls += check\n",
        "  prev_lbls += (1 - check)\n",
        "print('\\nnew_lbls: ', new_lbls)\n",
        "print('\\nprev_lbls: ', prev_lbls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBH-2kz4SaS2"
      },
      "outputs": [],
      "source": [
        "#@title Run inference with trained classifier. { vertical-output: true }\n",
        "\n",
        "output_csv_filepath = ''  #@param {type:'string'}\n",
        "logit_threshold = 1.0  #@param\n",
        "# Set labels to a tuple of desired labels if you want to run inference on a\n",
        "# subset of the labels.\n",
        "labels = None  #@param\n",
        "\n",
        "classifier.write_inference_csv(\n",
        "    linear_classifier, db, output_csv_filepath, logit_threshold, labels=labels)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}